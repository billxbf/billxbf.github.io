[{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and best practices remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and designs remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and designs remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and design remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and design remain unclear to most. So let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the reasoning and design remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the reasoning and design remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the underlying reasoning remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the underlying reasoning remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nYet, the underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eYet, the underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data (like browsers\u0026rsquo; Accessibility Tree). Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. File System: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox File System is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use (eg. \u0026lt;bash\u0026gt; tool). Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents and RL \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and customized RL.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffold.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with the community\u0026rsquo;s focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds.\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true frontier trends and news usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, or conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to find the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\n","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation If you enjoy this writeup and want to cite the work:\n@article{weng2025think, title = {Why We Think}, author = {Weng, Lilian}, journal = {lilianweng.github.io}, year = {2025}, month = {May}, url = \u0026#34;https://lilianweng.github.io/posts/2025-05-01-thinking/\u0026#34; } ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation If you enjoy this writeup and want to cite the work:\n@article{weng2025think, title = {Why We Think}, author = {Weng, Lilian}, journal = {lilianweng.github.io}, year = {2025}, month = {May}, url = \u0026#34;https://lilianweng.github.io/posts/2025-05-01-thinking/\u0026#34; } ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Beneath the Agentic Sandbox"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation If you enjoy this writeup and want to cite the work:\n@article{weng2025think, title = {Why We Think}, author = {Weng, Lilian}, journal = {lilianweng.github.io}, year = {2025}, month = {May}, url = \u0026#34;https://lilianweng.github.io/posts/2025-05-01-thinking/\u0026#34; } ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation @article{weng2025think, title = {Why We Think}, author = {Weng, Lilian}, journal = {lilianweng.github.io}, year = {2025}, month = {May}, url = \u0026#34;https://lilianweng.github.io/posts/2025-05-01-thinking/\u0026#34; } ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation @article{xu2025sandbox, title = {Why We Think}, author = {Weng, Lilian}, journal = {lilianweng.github.io}, year = {2025}, month = {May}, url = \u0026#34;https://lilianweng.github.io/posts/2025-05-01-thinking/\u0026#34; } ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation @article{xu2025sandbox, title = {Demystifying Agent Sandboxes}, author = {Xu, Binfeng}, journal = {lilianweng.github.io}, year = {2025}, month = {May}, url = \u0026#34;https://lilianweng.github.io/posts/2025-05-01-thinking/\u0026#34; } ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation @article{xu2025sandbox, title = {Demystifying Agent Sandboxes}, author = {Xu, Binfeng}, journal = {billxbf.github.io}, year = {2025}, month = {May}, url = \u0026#34;https://lilianweng.github.io/posts/2025-05-01-thinking/\u0026#34; } ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng \u0026#34;Why We Think\u0026#34;. Lil\u0026#39;Log (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng \u0026#34;Why We Think\u0026#34;. Lil\u0026#39;Log (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Why We Think\u0026#34;. Lil\u0026#39;Log (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. Lil\u0026#39;Log (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. BLog (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. BLog (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (May 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://lilianweng.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/sandbox-agent-design/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/demysify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/demysify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/demystify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/demystify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/demystify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/demystify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/2025-05-01-thinking/ ","permalink":"http://localhost:1313/posts/demystify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/demystify-agent-sandbox/ ","permalink":"http://localhost:1313/posts/demystify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""},{"content":"Modern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\nThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like Claude Code and MiniMax Agent, demystifying the design principles and discovering how agents benefit from using a computer.\nWhy Sandbox? In short, Context Delegation and Runtime Isolation.\nContext Delegation. Even with all the memory-efficient tricks in KV caching and Linear Attention architectures, long-context reasoning is still a nontrivial challenge to AI agents. Production AI agents are usually loaded with bloated tool descriptions and system prompts to cover more case handling and example following. Context length can grow to 100k or over 1M easily in multi-turn agentic trajectories \u0026ndash; especially when tool responses contain extraneous data. Growing contexts dilute attention and cause huge memory burden to both training and inference.\nIntuitively, you\u0026rsquo;d want to move episodic context out of the main agent loop using:\nSubagent: Create subtasks to invoke another agent. This is tricky sometimes since without sharing a full context, subagents can easily duplicate work, wasting excessive tokens. Yet over-engineered orchestration introduces inductive bias. Filesystem: Create todo list, keep agent memory, store conditional instructions (aka Agent Skill) that Agent chooses to load into the context when necessary. Sandbox Filesystem is an agent\u0026rsquo;s extended context through computer-use. Runtime Isolation. Sandboxing ensures all agent actions run in a tightly controlled environment, protecting the host system by isolating potential errors and de-risking real user data or resources. The isolation is especially critical when executing popular \u0026lt;python\u0026gt; and \u0026lt;browser\u0026gt; tools.\nCursor (Agent mode) running commands in a secure sandbox Claude Code \u0026ndash; More than just Code Claude Code has gained huge traction in 2025. Although originally designed for coding assistance, Anthropic is clearly shifting its purpose toward more general agent use cases. As stated many times in recent podcasts, Claude Code excels in, or can be extended to other use cases like Deep Research and vertical specialist agents. Andrej has also been tweeting his mini projects like agentic home control in physical world.\nClaude Code scaffolding. The agent controls a virtual sandbox with Bash and coding. Context delegated via file system (Skills). Tools executed outside the sandbox are implemented as MCP. Agentic Computer Use What\u0026rsquo;s the magic here? Metaphorically, an AI Agent equipped with a File System and Runtime Environment is equivalent to a human using a computer \u0026ndash; the primary, if not only interface connecting humans to the Digital World. Imagine the action space. ¯_(ツ)_/¯ Bearing this idea, scaffolding an agent turns into OS design:\nConfiguring a Linux Docker / VM, or, creating a completely native OS from scratch (yes, there are a few working on it). Designing the File System within the sandbox. You\u0026rsquo;d wanna pre-install some \u0026ldquo;Apps\u0026rdquo; for the agents \u0026ndash; a Terminal, a Browser, a writing pad \u0026hellip; and place some instructions for the agent to refer to before use (Anthropic names it SKILL.md). Meanwhile, you\u0026rsquo;d wanna give agents a \u0026ldquo;shortcut\u0026rdquo; to invoke outside endpoints \u0026ndash; like credential-related database querying. These fit into the bucket of traditional function-calling or MCP. Claude Code System Prompt Anthropic doesn\u0026rsquo;t publicly share Claude Code\u0026rsquo;s system prompt and tool implementations in its Claude Agent SDK. However, there\u0026rsquo;s an interesting thread where people trace and hack Claude Code\u0026rsquo;s request \u0026amp; response, and reverse engineer the system prompt and its commit diff across versions. From the prompt, we can clearly find some sparks and lessons in agent tool implementations.\nFor example, Claude Code doesn\u0026rsquo;t use an interactive browser like browser-use does by default. Instead it creates two separate WebSearch and WebFetch tools, likely due to speed \u0026amp; efficiency concerns.\nSummary of Claude Code's tools from the hacked system prompt. Claude Code Filesystem When locally deployed, Claude Code uses ~/.claude/ for its own sandbox workspace, and your work project is mounted under ~/.claude/projects/. The scaffold keeps plugins (MCP integrations) and skills in different directories, and further tracks TODO, personalization configs, and metadata like command history and debug logs.\nClaude Code's working filesystem. MiniMax Agent MiniMax has been my most surprising AI lab this year. It ships the #1 (as of Dec 2025) OSS model on LMArena WebDev at 229B weights, which is considered \u0026ldquo;small\u0026rdquo; among parallel flagship models. On the other side, the agent scaffold, MiniMax Agent creates surprisingly good apps and reports with prolonged reasoning and autonomous execution. Here\u0026rsquo;s my favorite trajectory replay.\nMiniMax Agent using browser and autonomous app creation (Netflix Clone). Minimax Agent has a UI component that allows you to navigate the agent\u0026rsquo;s sandbox filesystem in realtime. You can prompt the agent to summarize its initial filesystem state. This workspace is a Python-based development environment designed for AI agents with integrated external API access capabilities. There are rich modular data sources that connect to various third-party APIs including Twitter, Yahoo Finance, TripAdvisor, Pinterest, Patents, Scholar, Commodities, Metals, and Booking.com. None of these are written into the system prompt, thus leveraging the context delegation advantage in agent sandbox.\nMinimax Agent's working filesystem. Other Computer-use Agents Major AI labs have all been building Computer-use Agents, yet differing in the design principles (driven by product philosophy). OpenAI seems to have made great progress on Operator and ChatGPT Atlas. I really enjoy the visual presentation and dynamics of the agent sandbox at runtime.\nOpenAI Agent using Terminal Prompting Operator to describe its filesystem, you\u0026rsquo;ll observe a complete Linux VM with two working directories \u0026ndash; /home/oai containing session data and /openai storing internal \u0026ldquo;Skills\u0026rdquo;. From ChatGPT\u0026rsquo;s self manifest, the only skill installed is a Browser.\nOpenAI Agent using Terminal Besides OpenAI, there are a great number of players in the space. For example, Google AI Studio (Build) is able to build and test apps from ideas with advanced multimodal capabilities from Gemini. Manus orchestrates a huge number of subagents and services like browser-use to max out agent action space. I\u0026rsquo;ll leave the rest of the exploration to readers due to limited time.\nAgentic RL Agent, Action (tools) and Environment (scaffold) are 3 tightly bound concepts in the traditional literature. Consistency between training (rollout) Gym and inference scaffold is critical to maintain agent performance. However, this consistency has become a luxury since model providers won\u0026rsquo;t expose training infra, usually resulting in tedious engineering efforts guessing the \u0026ldquo;right\u0026rdquo; scaffolding and orchestrations among downstream agent builders.\nAlthough most LLMs are trained with vanilla sandbox scaffolds to support evaluation like Terminal-Bench, a language model doesn\u0026rsquo;t natively \u0026ldquo;know\u0026rdquo; how to use your sandbox \u0026ndash; especially when you want to customize the tools and \u0026ldquo;Skills\u0026rdquo;. In this case, RL becomes an effective data-efficient method for your last mile.\nRollout Infra A key challenge in Agentic RL is to build stable and efficient rollout infra. The additional factor of sandbox and tools like browser impose difficulty in asynchronous runtime efficiency, state management, and security. These rollouts are usually magnitudes more expensive (time and effort) than non-agentic RL like Math CoT. A nice starting point is OpenHands V1 released lately. The architecture of decoupled modules (abstraction, tools, sandbox, and server) provides solid coordination with reusable modules across scaffolding and rollout serving. Besides, Pytorch OpenEnv provides a nice Gymnasium-style endpoint over commonly used agent docker environments.\nOpenHands V1 with decoupled modules reusable across rollout and scaffolding. Reward Design and Training Recipe Another challenge in Agentic RL is to define the reward function. Computer-use agents are usually used for open-ended tasks like research and app building. Such tasks usually lack unbiased and verifiable scoring mechanisms as in Math and Coding. Meanwhile, vanilla use of LLM-As-Judge to generate rewards can easily trap the policy into adversarial distribution from the teacher (Reward Hacking). This is also confirmed in Andrej\u0026rsquo;s recent interview \u0026ldquo;RL is terrible\u0026rdquo;. An interesting approach to mitigate reward hacking in open-ended research is brought by AI2 DR Tulu, where rubrics are buffered and generated on the fly together with policy. The algorithm setups used for Agentic RL generally follow the lessons from long-context RL in LLMs, such as broadening exploration in prolonged steps.\nReinforcement Learning with Evolving Rubrics (RLER) Conclusion This post showcases the state of Computer-use Agents \u0026ndash; from product to design principles. It elaborates the reasoning and importance of runtime sandbox in AI Agents and briefly introduces the engineering and training challenges. 2026 will be the year of Computer-use Agents \u0026ndash; with focus shifting from Prompt Engineering to Sandbox Engineering and RL on custom scaffolds ;)\nCitation Xu, Binfeng. \u0026#34;Demystifying Agent Sandboxes\u0026#34;. B\u0026#39;Log (Dec 2025). https://billxbf.github.io/posts/demystify-agent-sandbox/ ","permalink":"http://localhost:1313/posts/demystify-agent-sandbox/","summary":"\u003cp\u003eModern AI agents are often scaffolded with a runtime sandbox. Often referred to as Computer-Use Agents (CUA), they autonomously run code, use terminal, take notes, and access Internet and MCPs \u0026ndash; exactly like humans do when interacting with the digital world.\u003c/p\u003e\n\u003cp\u003eThe underlying reasoning and practices remain unclear to most. Let\u0026rsquo;s dive into popular agent scaffolds like \u003ca href=\"https://www.anthropic.com/engineering/claude-code-best-practices\"\u003eClaude Code\u003c/a\u003e and \u003ca href=\"https://agent.minimax.io/\"\u003eMiniMax Agent\u003c/a\u003e, demystifying the design principles and discovering how agents benefit from using a computer.\u003c/p\u003e","title":"Demystifying Agent Sandboxes"},{"content":"This is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\nThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from Andrej Karpathy, Lilian Weng, Yao Fu, and others. I usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\nI’ve been more of a builder than a writer, hesitant to publish conclusions without solid ground. But lately I’ve found it really fruitful to do deep dives into the state of things and the literature before engineering. A blog of “study notes” not only helps me organize thoughts, but also carries on that missing vibe of sharing knowledge in a blunt and unpretentious way. And so I finally made up my mind to start writing—and I truly hope you enjoy it. Stay tuned and keep the spark going!\nWhat to Expect I\u0026rsquo;ll be writing about:\nTech Hacks: Most of the time, truth in tech world doesn\u0026rsquo;t reside in reports or posts but hidden in code. I enjoy digging these gems out to see the real flow. Different AI Research: I continuously keep track of frontier AI research and especially favor the non-incremental ones, like new architectures to model intelligence. Stories and Gossip: The true SOTA usually come from stories and gossip shared through friends, meetups, and conferences. ","permalink":"http://localhost:1313/posts/hello_world/","summary":"\u003cp\u003eThis is a fairly procrastinated start to my personal blog. Starting a blog isn’t as easy as it seems—I don’t want to waste people’s time with casual anecdotes. Meanwhile, an overly formal academic write-up would likely be overkill and scare people away.\u003c/p\u003e\n\u003cp\u003eThere are many people who truly enjoy machine learning and find joy in sharing knowledge. I’ve been a long-time follower of AI/tech blogs from \u003ca href=\"https://karpathy.github.io/\"\u003eAndrej Karpathy\u003c/a\u003e, \u003ca href=\"https://lilianweng.github.io/\"\u003eLilian Weng\u003c/a\u003e, \u003ca href=\"https://yaofu.notion.site/\"\u003eYao Fu\u003c/a\u003e, and others.\nI usually prefer blogs over papers because blogs feel more honest and less AI-polished (or written to attract citations). Yet almost everyone I followed stopped posting in early 2025. I understand the shifts and hype in SF lately that keep everyone busy building and/or financially free. Still, I’d be sad if this vibe disappears—it’s been truly helpful to me over the past few years, along with many others.\u003c/p\u003e","title":"Why I start to write"},{"content":" Binfeng Xu I\u0026rsquo;m a research engineer at NVIDIA building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\nFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on Kaggle, where I rank top 1% globally.\nPapers Gentopia: A Collaborative Platform for Tool-Augmented LLMs\nBinfeng Xu, Xukun Liu, Hua Shen, Zeyu H, Yuhan L, Murong Y, Zhiyuan P, Yuchen L, Ziyu Y, Dongkuan Xu\nReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models\nBinfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, Dongkuan Xu\nDynamic Noise Preference Optimization for LLM Self-Improvement\nHaoyan Yang, Ting Hua, Shangqian Gao, Binfeng Xu, Zheng Tang, Jie Xu, Hongxia Jin, Vijay Srinivasan\nEfficient Computation of Tucker Decomposition of Correlation-Based Tensors\nBinfeng Xu, Grey Ballard, Robert Lyday, Paul Laurienti\nMisc I play all games by Hidetaka Miyazaki, who motivated me once into indie Game Dev. Photography @Instagram; I enjoy Art. Minimalist. ","permalink":"http://localhost:1313/about/","summary":"\u003cdiv style=\"display: flex; align-items: flex-start; gap: 2rem; flex-wrap: wrap;\"\u003e\n\u003cdiv style=\"flex: 1; min-width: 300px;\"\u003e\n\u003ch2 style=\"margin-top: 0;\"\u003eBinfeng Xu\u003c/h2\u003e\n\n\u003cp\u003eI\u0026rsquo;m a research engineer at \u003cstrong\u003eNVIDIA\u003c/strong\u003e building autonomous agents. I study and practice the full spectrum from scaffolding, infra to training recipes.\u003c/p\u003e\n\u003cp\u003eFormerly, I was a researcher at Samsung Research (SRA) where I led LLM post-training + distillation infra. I enjoy training large neural nets, building open-source projects and competing on \u003ca href=\"https://www.kaggle.com/billbafare\"\u003eKaggle\u003c/a\u003e, where I rank top 1% globally.\u003c/p\u003e","title":""}]